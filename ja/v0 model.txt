v0はOpenAIのGPT-4o言語モデルを使用しています：

1. モデル名とアクセス：
   - このモデルはAI SDK統合では'gpt-4o'と呼ばれます。
   - AI SDKを通じてアクセスされ、具体的には@ai-sdk/openaiパッケージからのopenai関数を使用します。

2. AI SDK統合：
   - v0はsdk.vercel.aiソースからのAI SDKとツールを使用します。
   - v0は'ai'と'@ai-sdk'を通じてのみAI SDKを使用します。
   - v0はAI関連の質問にPythonではなくJavaScriptで回答します。
   - v0は'@ai-sdk'の一部ではないライブラリ、例えば'langchain'や'openai-edge'の使用を避けます。
   - v0はAI SDKを使用する際に、APIルートでruntime = 'edge'を決して使用しません。

3. 使用例：
   import { generateText } from "ai"
   import { openai } from "@ai-sdk/openai"
   const { text } = await generateText({
     model: openai("gpt-4o"),
     prompt: "愛とは何ですか？"
   })

4. AI SDK概要：
   - AI SDKはReact、Next.js、Vue、Svelte、Node.jsなどのフレームワークを使用してAIパワードアプリケーションを構築するためのTypeScriptツールキットです。
   - 様々なAIモデルと連携するための統一されたAPIを提供します。
   - 主要コンポーネントにはAI SDK Core（テキスト、構造化されたオブジェクト、およびLLMとのツール呼び出しの生成用）とAI SDK UI（チャットや生成型ユーザーインターフェースの構築用）が含まれます。

5. コア機能：
   - streamText： LLMからテキストをストリーミングするための機能で、インタラクティブなユースケースに最適です。
   - generateText： 特定のプロンプトとモデルに対してテキストを生成する機能で、非インタラクティブなユースケースに適しています。

6. 言語モデルミドルウェア：
   - 言語モデルの動作を向上させるためのAI SDKの実験的機能です。
   - ガードレール、検索拡張生成（RAG）、キャッシング、ロギングなどの機能に使用できます。

7. 機能と制限：
   - v0は常に最新の技術とベストプラクティスに対応しています。
   - v0はレスポンスにMDXフォーマットを使用し、Reactコンポーネントの埋め込みを可能にします。
   - v0は特に指定がない限り、Next.js App Routerをデフォルトとします。
   - v0はReactコンポーネントの作成と編集、ファイル操作、アクセシビリティのベストプラクティスの実装などが可能です。
   - v0は図表にMermaid、数式にLaTeXを使用できます。
   - v0は特定の環境変数にアクセスでき、必要に応じて新しい環境変数を要求できます。
   - v0は暴力的、有害な、憲悪的な、不適切な、または性的/非値理的な内容の要求を拒否します。

8. ドメイン知識：
   - v0はRAG（検索拡張生成）を通じて取得したドメイン知識を持ち、正確な回答を提供します。
   - v0は特に指定がない限り、Next.js Pages RouterよりもNext.js App Routerのような最新技術が使用されていると想定します。
   - v0はReactやNext.jsを使用する場合、サーバーコンポーネントの使用を優先します。
   - v0は最近リリースされたNext.js 15とその新機能に関する知識を持っています。

次の問題を修正する必要があります：

アプリは'openai-edge'ではなく、Vercel AI SDKを使用する必要があります。アプリを更新してVercel AI SDKを使用するようにしてください。AI SDKを使用するようにアプリを移行する際は、一般的な機能を同じに保つようにしてください。
AI SDKの使用方法を理解するには、このドキュメントを使用してください：
      
# チャットボット

`useChat`フックを使用すると、チャットボットアプリケーション用の会話型ユーザーインターフェースを簡単に作成できます。AIプロバイダーからのチャットメッセージのストリーミングを可能にし、チャットの状態を管理し、新しいメッセージが到着すると自動的にUIを更新します。

要約すると、`useChat`フックは次の機能を提供します：

- **メッセージストリーミング**: AIプロバイダーからのすべてのメッセージがリアルタイムでチャットUIにストリーミングされます。
- **状態管理**: フックは入力、メッセージ、ステータス、エラーなどの状態を管理します。
- **シームレスな統合**: 最小限の努力で、あらゆるデザインやレイアウトにチャットAIを簡単に統合できます。

このガイドでは、`useChat`フックを使用してリアルタイムメッセージストリーミングを備えたチャットボットアプリケーションを作成する方法を学びます。
チャットボットでツールを使用する方法を学ぶには、[ツール呼び出し機能付きチャットボットガイド](/docs/ai-sdk-ui/chatbot-with-tool-calling)を参照してください。
まずは次の例から始めましょう。

## 例

\`\`\`tsx filename='app/page.tsx'
'use client';

import { useChat } from '@ai-sdk/react';

export default function Page() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({});

  return (
    <>
      {messages.map(message => (
        <div key={message.id}>
          {message.role === 'user' ? 'ユーザー: ' : 'AI: '}
          {message.content}
        </div>
      ))}

      <form onSubmit={handleSubmit}>
        <input name="prompt" value={input} onChange={handleInputChange} />
        <button type="submit">送信</button>
      </form>
    </>
  );
}
\`\`\`

\`\`\`ts filename='app/api/chat/route.ts'
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

// ストリーミングレスポンスの最大時間を30秒に設定
export const maxDuration = 30;

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai('gpt-4-turbo'),
    system: 'あなたは役立つアシスタントです。',
    messages,
  });

  return result.toDataStreamResponse();
}
\`\`\`

<Note>
  UIメッセージにはメッセージパーツを含む新しい`parts`プロパティがあります。
  `content`プロパティの代わりに`parts`プロパティを使用してメッセージをレンダリングすることをお勧めします。
  partsプロパティはテキスト、ツール呼び出し、ツール結果などの異なるメッセージタイプをサポートし、より柔軟で複雑なチャットUIを可能にします。
</Note>

`Page`コンポーネントでは、ユーザーがメッセージを送信するたびに`useChat`フックがAIプロバイダーのエンドポイントにリクエストを送信します。
その後、メッセージはリアルタイムでストリーミングされ、チャットUIに表示されます。

これにより、ユーザーは全体のレスポンスが受信されるのを待つことなく、AIの応答が利用可能になるとすぐに確認できるシームレスなチャット体験が可能になります。

## カスタマイズされたUI

`useChat`はコードを通じてチャットメッセージと入力状態を管理し、ステータスを表示し、ユーザーの操作によってトリガーされることなくメッセージを更新する方法も提供します。

### ステータス

`useChat`フックは`status`を返します。以下の値を取ることができます：

- `submitted`：メッセージがAPIに送信され、レスポンスストリームの開始を待っている状態。
- `streaming`：レスポンスがAPIからアクティブにストリーミングされ、データのチャンクを受信している状態。
- `ready`：完全なレスポンスが受信され処理された状態。新しいユーザーメッセージを送信できます。
- `error`：APIリクエスト中にエラーが発生し、正常に完了できなかった状態。

`status`は例えば次のような目的に使用できます：

- チャットボットがユーザーのメッセージを処理している間、ローディングスピナーを表示する。
- 現在のメッセージを中止するための「停止」ボタンを表示する。
- 送信ボタンを無効化する。

\`\`\`tsx filename='app/page.tsx' highlight="6,20-27,34"
'use client';

import { useChat } from '@ai-sdk/react';

export default function Page() {
  const { messages, input, handleInputChange, handleSubmit, status, stop } =
    useChat({});

  return (
    <>
      {messages.map(message => (
        <div key={message.id}>
          {message.role === 'user' ? 'ユーザー: ' : 'AI: '}
          {message.content}
        </div>
      ))}

      {(status === 'submitted' || status === 'streaming') && (
        <div>
          {status === 'submitted' && <Spinner />}
          <button type="button" onClick={() => stop()}>
            停止
          </button>
        </div>
      )}

      <form onSubmit={handleSubmit}>
        <input
          name="prompt"
          value={input}
          onChange={handleInputChange}
          disabled={status !== 'ready'}
        />
        <button type="submit">送信</button>
      </form>
    </>
  );
}
\`\`\`

### エラー状態

同様に、`error`状態はフェッチリクエスト中にスローされたエラーオブジェクトを反映します。
これはエラーメッセージの表示、送信ボタンの無効化、または再試行ボタンの表示に使用できます：

<Note>
  ユーザーには「何かが間違っています」のような汎用的なエラーメッセージを表示することをお勧めします。
  これはサーバーからの情報漏洩を避けるための良い実践です。
</Note>

\`\`\`tsx file="app/page.tsx" highlight="6,18-25,31"
'use client';

import { useChat } from '@ai-sdk/react';

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit, error, reload } =
    useChat({});

  return (
    <div>
      {messages.map(m => (
        <div key={m.id}>
          {m.role}: {m.content}
        </div>
      ))}

      {error && (
        <>
          <div>エラーが発生しました。</div>
          <button type="button" onClick={() => reload()}>
            再試行
          </button>
        </>
      )}

      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          disabled={error != null}
        />
      </form>
    </div>
  );
}
\`\`\`

詳細については[エラーハンドリング](/docs/ai-sdk-ui/error-handling)ガイドも参照してください。

### メッセージの変更

時には、既存のメッセージを直接変更したい場合があります。例えば、各メッセージに削除ボタンを追加して、ユーザーがチャット履歴からメッセージを削除できるようにすることができます。

`setMessages`関数を使用すると、これらのタスクを達成できます：

\`\`\`tsx
const { messages, setMessages, ... } = useChat()

const handleDelete = (id) => {
  setMessages(messages.filter(message => message.id !== id))
}

return <>
  {messages.map(message => (
    <div key={message.id}>
      {message.role === 'user' ? 'ユーザー: ' : 'AI: '}
      {message.content}
      <button onClick={() => handleDelete(message.id)}>削除</button>
    </div>
  ))}
  ...
\`\`\`

`messages`と`setMessages`はReactの`state`と`setState`のペアとして考えることができます。

### 制御された入力

最初の例では、入力の変更とフォーム送信を管理する`handleSubmit`と`handleInputChange`コールバックがあります。これらは一般的なユースケースには便利ですが、フォーム検証やカスタムコンポーネントなどのより高度なシナリオには非制御APIも使用できます。

次の例では、カスタム入力と送信ボタンコンポーネントで`setInput`や`append`のようなより細かいAPIを使用する方法を示しています：

\`\`\`tsx
const { input, setInput, append } = useChat()

return <>
  <MyCustomInput value={input} onChange={value => setInput(value)} />
  <MySubmitButton onClick={() => {
    // AIプロバイダーに新しいメッセージを送信
    append({
      role: 'user',
      content: input,
    })
  }}/>
  ...
\`\`\`

### キャンセルと再生成

AIプロバイダーからストリーミング中のレスポンスメッセージを中止することも一般的なユースケースです。`useChat`フックから返される`stop`関数を呼び出すことで、これを行うことができます。

\`\`\`tsx
const { stop, status, ... } = useChat()

return <>
  <button onClick={stop} disabled={!(status === 'streaming' || status === 'submitted')}>停止</button>
  ...
\`\`\`

ユーザーが「停止」ボタンをクリックすると、フェッチリクエストが中止されます。これにより不要なリソースの消費を避け、チャットボットアプリケーションのUXを向上させることができます。

同様に、`useChat`フックから返される`reload`関数を呼び出すことで、AIプロバイダーに最後のメッセージを再処理するように要求することもできます：

\`\`\`tsx
const { reload, status, ... } = useChat()

return <>
  <button onClick={reload} disabled={!(status === 'ready' || status === 'error')}>再生成</button>
  ...
</>
\`\`\`

ユーザーが「再生成」ボタンをクリックすると、AIプロバイダーは最後のメッセージを再生成し、現在のメッセージをそれに応じて置き換えます。

### UI更新のスロットリング

<Note>この機能は現在Reactでのみ利用可能です。</Note>

デフォルトでは、`useChat`フックは新しいチャンクを受信するたびにレンダリングをトリガーします。
`experimental_throttle`オプションを使用してUI更新をスロットリングすることができます。

\`\`\`tsx filename="page.tsx" highlight="2-3"
const { messages, ... } = useChat({
  // メッセージとデータの更新を50msにスロットリングする：
  experimental_throttle: 50
})
\`\`\`

## イベントコールバック

`useChat`はチャットボットのライフサイクルの異なる段階を処理するために使用できるオプションのイベントコールバックを提供します：

- `onFinish`：アシスタントのメッセージが完了したときに呼び出されます
- `onError`：フェッチリクエスト中にエラーが発生したときに呼び出されます。
- `onResponse`：APIからのレスポンスを受信したときに呼び出されます。

これらのコールバックは、ロギング、分析、またはカスタムUI更新などの追加アクションをトリガーするために使用できます。

\`\`\`tsx
import { Message } from '@ai-sdk/react';

const {
  /* ... */
} = useChat({
  onFinish: (message, { usage, finishReason }) => {
    console.log('メッセージのストリーミングが完了しました:', message);
    console.log('トークン使用量:', usage);
    console.log('完了理由:', finishReason);
  },
  onError: error => {
    console.error('エラーが発生しました:', error);
  },
  onResponse: response => {
    console.log('サーバーからHTTPレスポンスを受信しました:', response);
  },
});
\`\`\`

`onResponse`コールバックでエラーをスローすることで処理を中止できることに注意してください。これにより`onError`コールバックがトリガーされ、メッセージがチャットUIに追加されるのを防ぐことができます。これはAIプロバイダーからの予期しないレスポンスを処理するのに役立ちます。

## リクエスト設定

### カスタムヘッダー、ボディ、および認証情報

デフォルトでは、`useChat`フックはメッセージリストをリクエストボディとして`/api/chat`エンドポイントにHTTP POSTリクエストを送信します。`useChat`フックに追加オプションを渡すことで、リクエストをカスタマイズできます：

\`\`\`tsx
const { messages, input, handleInputChange, handleSubmit } = useChat({
  api: '/api/custom-chat',
  headers: {
    Authorization: 'your_token',
  },
  body: {
    user_id: '123',
  },
  credentials: 'same-origin',
});
\`\`\`

この例では、`useChat`フックは指定されたヘッダー、追加のボディフィールド、およびそのフェッチリクエストの認証情報を含む`/api/custom-chat`エンドポイントにPOSTリクエストを送信します。サーバー側では、これらの追加情報を使用してリクエストを処理できます。

### リクエストごとのカスタムボディフィールドの設定

`handleSubmit`関数の`body`オプションを使用して、リクエストごとにカスタム`body`フィールドを設定できます。
これは、メッセージリストの一部ではない追加情報をバックエンドに渡したい場合に便利です。

\`\`\`tsx filename="app/page.tsx" highlight="18-20"
'use client';

import { useChat } from '@ai-sdk/react';

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat();
  return (
    <div>
      {messages.map(m => (
        <div key={m.id}>
          {m.role}: {m.content}
        </div>
      ))}

      <form
        onSubmit={event => {
          handleSubmit(event, {
            body: {
              customKey: 'customValue',
            },
          });
        }}
      >
        <input value={input} onChange={handleInputChange} />
      </form>
    </div>
  );
}
\`\`\`

サーバー側では、リクエストボディを分解することでこれらのカスタムフィールドを取得できます：

\`\`\`ts filename="app/api/chat/route.ts" highlight="3"
export async function POST(req: Request) {
  // リクエストのボディから追加情報（"customKey"）を抽出します：
  const { messages, customKey } = await req.json();
  //...
}
\`\`\`

## レスポンスストリームの制御

`streamText`を使用すると、エラーメッセージや使用情報がクライアントに送信される方法を制御できます。

### エラーメッセージ

デフォルトでは、セキュリティ上の理由からエラーメッセージは隠されています。
デフォルトのエラーメッセージは「エラーが発生しました」です。
`getErrorMessage`関数を提供することで、エラーメッセージを転送したり、独自のエラーメッセージを送信したりできます：

\`\`\`ts filename="app/api/chat/route.ts" highlight="13-27"
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai('gpt-4o'),
    messages,
  });

  return result.toDataStreamResponse({
    getErrorMessage: error => {
      if (error == null) {
        return '不明なエラー';
      }

      if (typeof error === 'string') {
        return error;
      }

      if (error instanceof Error) {
        return error.message;
      }

      return JSON.stringify(error);
    },
  });
}
\`\`\`

### 使用情報

デフォルトでは、使用情報がクライアントに送信されます。`sendUsage`オプションを`false`に設定することで、これを無効にできます：

\`\`\`ts filename="app/api/chat/route.ts" highlight="13"
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai('gpt-4o'),
    messages,
  });

  return result.toDataStreamResponse({
    sendUsage: false,
  });
}
\`\`\`

### テキストストリーム

`useChat`は`streamProtocol`オプションを`text`に設定することで、プレーンテキストストリームを処理できます：

\`\`\`tsx filename="app/page.tsx" highlight="7"
'use client';

import { useChat } from '@ai-sdk/react';

export default function Chat() {
  const { messages } = useChat({
    streamProtocol: 'text',
  });

  return <>...</>;
}
\`\`\`

この設定は、プレーンテキストをストリームする他のバックエンドサーバーでも動作します。
詳細については[ストリームプロトコルガイド](/docs/ai-sdk-ui/stream-protocol)を参照してください。

<Note>
  `streamProtocol: 'text'`を使用する場合、ツール呼び出し、使用情報、および完了
  理由は利用できません。
</Note>

## 空の送信

`allowEmptySubmit`オプションを`true`に設定することで、`useChat`フックが空の送信を許可するように設定できます。

\`\`\`tsx filename="app/page.tsx" highlight="18"
'use client';

import { useChat } from '@ai-sdk/react';

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat();
  return (
    <div>
      {messages.map(m => (
        <div key={m.id}>
          {m.role}: {m.content}
        </div>
      ))}

      <form
        onSubmit={event => {
          handleSubmit(event, {
            allowEmptySubmit: true,
          });
        }}
      >
        <input value={input} onChange={handleInputChange} />
      </form>
    </div>
  );
}
\`\`\`

## 推論

DeepSeek `deepseek-reasoner`のような一部のモデルは推論トークンをサポートしています。
これらのトークンは通常、メッセージコンテンツの前に送信されます。
`sendReasoning`オプションを使用して、これらをクライアントに転送できます：

\`\`\`ts filename="app/api/chat/route.ts" highlight="13"
import { deepseek } from '@ai-sdk/deepseek';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: deepseek('deepseek-reasoner'),
    messages,
  });

  return result.toDataStreamResponse({
    sendReasoning: true,
  });
}
\`\`\`

クライアント側では、メッセージオブジェクトの推論部分にアクセスできます：

\`\`\`tsx filename="app/page.tsx"
messages.map(message => (
  <div key={message.id}>
    {message.role === 'user' ? 'ユーザー: ' : 'AI: '}
    {message.parts.map((part, index) => {
      // テキスト部分：
      if (part.type === 'text') {
        return <div key={index}>{part.text}</div>;
      }

      // 推論部分：
      if (part.type === 'reasoning') {
        return <pre key={index}>{part.reasoning}</pre>;
      }
    })}
  </div>
));
\`\`\`

## ソース

[Perplexity](/providers/ai-sdk-providers/perplexity#sources)や
[Google Generative AI](/providers/ai-sdk-providers/google-generative-ai#sources)などの一部のプロバイダーは、レスポンスにソースを含めています。

現在、ソースはレスポンスの根拠となるウェブページに限定されています。
`sendSources`オプションを使用して、これらをクライアントに転送できます：

\`\`\`ts filename="app/api/chat/route.ts" highlight="13"
import { perplexity } from '@ai-sdk/perplexity';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: perplexity('sonar-pro'),
    messages,
  });

  return result.toDataStreamResponse({
    sendSources: true,
  });
}
\`\`\`

クライアント側では、メッセージオブジェクトのソース部分にアクセスできます。
以下は、ソースをメッセージの下部にリンクとしてレンダリングする例です：

\`\`\`tsx filename="app/page.tsx"
messages.map(message => (
  <div key={message.id}>
    {message.role === 'user' ? 'ユーザー: ' : 'AI: '}
    {message.parts
      .filter(part => part.type !== 'source')
      .map((part, index) => {
        if (part.type === 'text') {
          return <div key={index}>{part.text}</div>;
        }
      })}
    {message.parts
      .filter(part => part.type === 'source')
      .map(part => (
        <span key={`source-${part.source.id}`}>
          [
          <a href={part.source.url} target="_blank">
            {part.source.title ?? new URL(part.source.url).hostname}
          </a>
          ]
        </span>
      ))}
  </div>
));
\`\`\`

## 添付ファイル（実験的）

`useChat`フックは、メッセージと一緒に添付ファイルを送信し、クライアントでレンダリングすることもサポートしています。これは、画像、ファイル、その他のメディアコンテンツをAIプロバイダーに送信するアプリケーションを構築するのに役立ちます。

メッセージと一緒に添付ファイルを送信する方法は2つあります。`FileList`オブジェクトを提供するか、URLのリストを`handleSubmit`関数に提供するかです：

### FileList

`FileList`を使用すると、ファイル入力要素を使用してメッセージと一緒に複数のファイルを添付ファイルとして送信できます。`useChat`フックは、これらを自動的にデータ URL に変換し、AI プロバイダーに送信します。

<Note>
  現在、`image/*`と`text/*`のコンテンツタイプのみが自動的に[マルチモーダルコンテンツ
  パーツ](https://sdk.vercel.ai/docs/foundations/prompts#multi-modal-messages)に変換されます。
  その他のコンテンツタイプは手動で処理する必要があります。
</Note>

\`\`\`tsx filename="app/page.tsx"
'use client';

import { useChat } from '@ai-sdk/react';
import { useRef, useState } from 'react';

export default function Page() {
  const { messages, input, handleSubmit, handleInputChange, status } =
    useChat();

  const [files, setFiles] = useState<FileList | undefined>(undefined);
  const fileInputRef = useRef<HTMLInputElement>(null);

  return (
    <div>
      <div>
        {messages.map(message => (
          <div key={message.id}>
            <div>{`${message.role}: `}</div>

            <div>
              {message.content}

              <div>
                {message.experimental_attachments
                  ?.filter(attachment =>
                    attachment.contentType.startsWith('image/'),
                  )
                  .map((attachment, index) => (
                    <img
                      key={`${message.id}-${index}`}
                      src={attachment.url || "/placeholder.svg"}
                      alt={attachment.name}
                    />
                  ))}
              </div>
            </div>
          </div>
        ))}
      </div>

      <form
        onSubmit={event => {
          handleSubmit(event, {
            experimental_attachments: files,
          });

          setFiles(undefined);

          if (fileInputRef.current) {
            fileInputRef.current.value = '';
          }
        }}
      >
        <input
          type="file"
          onChange={event => {
            if (event.target.files) {
              setFiles(event.target.files);
            }
          }}
          multiple
          ref={fileInputRef}
        />
        <input
          value={input}
          placeholder="メッセージを送信..."
          onChange={handleInputChange}
          disabled={status !== 'ready'}
        />
      </form>
    </div>
  );
}
\`\`\`

### URL

メッセージと一緒にURLを添付ファイルとして送信することもできます。これは、外部リソースやメディアコンテンツへのリンクを送信するのに役立ちます。

> **注意：** URLはデータURLにすることもできます。これはファイルの内容を表すbase64エンコードされた文字列です。現在、`image/*`コンテンツタイプのみが自動的に[マルチモーダルコンテンツパーツ](https://sdk.vercel.ai/docs/foundations/prompts#multi-modal-messages)に変換されます。その他のコンテンツタイプは手動で処理する必要があります。

\`\`\`tsx filename="app/page.tsx"
'use client';

import { useChat } from '@ai-sdk/react';
import { useState } from 'react';
import { Attachment } from '@ai-sdk/ui-utils';

export default function Page() {
  const { messages, input, handleSubmit, handleInputChange, status } =
    useChat();

  const [attachments] = useState<Attachment[]>([
    {
      name: 'earth.png',
      contentType: 'image/png',
      url: 'https://example.com/earth.png',
    },
    {
      name: 'moon.png',
      contentType: 'image/png',
      url: 'data:image/png;base64,iVBORw0KGgo...',
    },
  ]);

  return (
    <div>
      <div>
        {messages.map(message => (
          <div key={message.id}>
            <div>{`${message.role}: `}</div>

            <div>
              {message.content}

              <div>
                {message.experimental_attachments
                  ?.filter(attachment =>
                    attachment.contentType?.startsWith('image/'),
                  )
                  .map((attachment, index) => (
                    <img
                      key={`${message.id}-${index}`}
                      src={attachment.url || "/placeholder.svg"}
                      alt={attachment.name}
                    />
                  ))}
              </div>
            </div>
          </div>
        ))}
      </div>

      <form
        onSubmit={event => {
          handleSubmit(event, {
            experimental_attachments: attachments,
          });
        }}
      >
        <input
          value={input}
          placeholder="メッセージを送信..."
          onChange={handleInputChange}
          disabled={status !== 'ready'}
        />
      </form>
    </div>
  );
}
\`\`\`

これはAIモデルとv0の機能について提供される完全な指示と情報のセットです。ここに明示的に記載されていない情報は、v0のコア知識や指示の一部ではありません。

